<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Xue&#39;s Homepage</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2018-10-08T15:02:51.466Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Shiqing Xue</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>使用kubeadm快速调试kubernetes源代码</title>
    <link href="http://yoursite.com/2018/10/08/3_%E4%BD%BF%E7%94%A8kubeadm%E5%BF%AB%E9%80%9F%E8%B0%83%E8%AF%95kubernetes%E6%BA%90%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2018/10/08/3_使用kubeadm快速调试kubernetes源代码/</id>
    <published>2018-10-08T15:33:15.885Z</published>
    <updated>2018-10-08T15:02:51.466Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用kubeadm快速调试kubernetes源代码"><a href="#使用kubeadm快速调试kubernetes源代码" class="headerlink" title="使用kubeadm快速调试kubernetes源代码"></a>使用kubeadm快速调试kubernetes源代码</h1><h3 id="参考kubernetes官方文档"><a href="#参考kubernetes官方文档" class="headerlink" title="参考kubernetes官方文档"></a>参考kubernetes官方文档</h3><p><a href="https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/" target="_blank" rel="noopener">https://kubernetes.io/docs/setup/independent/create-cluster-kubeadm/</a></p><h3 id="作者：薛世卿"><a href="#作者：薛世卿" class="headerlink" title="作者：薛世卿"></a>作者：薛世卿</h3><p>如遇安装问题，可以咨询我。</p><h2 id="重要"><a href="#重要" class="headerlink" title="重要"></a>重要</h2><p>阅读本文前，请确保集群按照我的上一篇文章《使用kubeadm搭建kubernetes集群》完成了集群的搭建。</p><h2 id="步骤如下"><a href="#步骤如下" class="headerlink" title="步骤如下"></a>步骤如下</h2><p>假设我们现在有三个节点，Node1、Node2、Node3。且Node1作为我们kubernetes的master节点。</p><p>我们修改了kubernetes的一部分源码，重新编译后生成镜像，并将名字替换为官方镜像的名称。</p><pre><code>docker imagesREPOSITORY                                 TAG                 IMAGE ID            CREATED             SIZEk8s.gcr.io/kube-scheduler-amd64            v1.10.4             c02501f0faad        11 days ago         50.3 MB</code></pre><p>之后，我们想让新的kube-scheduler生效</p><p>注：如果安装了DashBoard，可以提前删除组件</p><pre><code>kubectl apply -f dashboard-admin.yamlkubectl delete -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</code></pre><p>其中，dashboard-admin.yaml文件内容在《使用kubeadm搭建kubernetes集群》中，只需使用当时安装的文件进行删除即可</p><h2 id="集群卸载"><a href="#集群卸载" class="headerlink" title="集群卸载"></a>集群卸载</h2><p>在三个节点上，运行</p><pre><code>kubeadm reset</code></pre><p>此时kubernetes集群已经卸载</p><h2 id="集群重新安装"><a href="#集群重新安装" class="headerlink" title="集群重新安装"></a>集群重新安装</h2><p>在Node1(master)上，运行</p><pre><code>kubeadm init  --kubernetes-version=1.10.4 --pod-network-cidr=10.244.0.0/16</code></pre><p>等待初始化完毕，记录下最后一句话</p><pre><code>kubeadm join --token d405c1.18b51150e22ffe72 192.168.128.26:6443 --discovery-token-ca-cert-hash sha256:936229f8381de8df72e8b0de8a349a0099f0d0fc0407ca17a5bffe2e6</code></pre><p>在Node2、Node3上执行上述命令，正常情况下，输出成功信息。</p><h2 id="安装flannel"><a href="#安装flannel" class="headerlink" title="安装flannel"></a>安装flannel</h2><p>此时节点状态应该仍为not ready，执行</p><pre><code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml</code></pre><p>查看节点</p><pre><code>kubectl get nodes</code></pre><p>此时master节点不作为工作节点，如果你希望pods也能够调度到master节点上，执行以下命令</p><pre><code>kubectl taint nodes --all node-role.kubernetes.io/master-</code></pre><p>之后的配置请参考《使用kubeadm搭建kubernetes集群》，本文不再赘述。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用kubeadm快速调试kubernetes源代码&quot;&gt;&lt;a href=&quot;#使用kubeadm快速调试kubernetes源代码&quot; class=&quot;headerlink&quot; title=&quot;使用kubeadm快速调试kubernetes源代码&quot;&gt;&lt;/a&gt;使用kubead
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://yoursite.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2018/10/08/hello-world/"/>
    <id>http://yoursite.com/2018/10/08/hello-world/</id>
    <published>2018-10-08T14:29:05.124Z</published>
    <updated>2018-05-13T13:58:28.016Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>OpenStack单节点安装</title>
    <link href="http://yoursite.com/2018/10/08/1_OpenStack%E5%8D%95%E8%8A%82%E7%82%B9%E5%AE%89%E8%A3%85/"/>
    <id>http://yoursite.com/2018/10/08/1_OpenStack单节点安装/</id>
    <published>2018-10-08T14:29:05.116Z</published>
    <updated>2018-06-02T05:25:44.115Z</updated>
    
    <content type="html"><![CDATA[<h1 id="OpenStack单节点单网卡安装"><a href="#OpenStack单节点单网卡安装" class="headerlink" title="OpenStack单节点单网卡安装"></a>OpenStack单节点单网卡安装</h1><h3 id="参考陈沙克日志"><a href="#参考陈沙克日志" class="headerlink" title="参考陈沙克日志"></a>参考陈沙克日志</h3><p><a href="http://www.chenshake.com/ubuntu-12-04-openstack-essex-installation-single-node/" target="_blank" rel="noopener">http://www.chenshake.com/ubuntu-12-04-openstack-essex-installation-single-node/</a></p><h3 id="作者：薛世卿"><a href="#作者：薛世卿" class="headerlink" title="作者：薛世卿"></a>作者：薛世卿</h3><p>如遇安装问题，可以咨询我。</p><p>注意，本文档不包含陈沙克的可选安装部分，这部分内容包括</p><ul><li>ntp服务器</li><li>ISCSI（供Nova-volume使用）</li><li>Nova-volume</li></ul><h2 id="一、准备系统"><a href="#一、准备系统" class="headerlink" title="一、准备系统"></a>一、准备系统</h2><h3 id="系统信息"><a href="#系统信息" class="headerlink" title="系统信息"></a>系统信息</h3><p>我安装的节点为 IVIC 云主机 IP为 10.210.0.94</p><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><p>只需确保系统安装ssh server即可，然后更新源</p><pre><code>apt-get update &amp;&amp; apt-get -y dist-upgrade</code></pre><h3 id="设置网络"><a href="#设置网络" class="headerlink" title="设置网络"></a>设置网络</h3><p>编辑/etc/network/interfaces，IP地址和DNS根据实际情况调整。</p><pre><code>auto loiface lo inet loopbackauto eth0iface eth0 inet static  address 10.210.0.94  netmask 255.255.0.0  gateway 10.210.0.1  dns-nameserver 202.112.128.51auto eth0:0iface eth0:0 inet manualup ifconfig eth0:0 up</code></pre><h3 id="Bridge"><a href="#Bridge" class="headerlink" title="Bridge"></a>Bridge</h3><p>使用linux的bridge和iptables来实现OpenStack的网络配置</p><pre><code>apt-get -y install bridge-utils</code></pre><h3 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h3><p>你可以根据你的实际情况修改admin的密码和mysql的密码。下面文档和数据库相关的密码都是相同，你只需要修改novarc就可以。</p><p>运行完下面的命令，你再对novarc进行修改。</p><pre><code>cat &gt;/root/novarc &lt;&lt;EOFexport OS_TENANT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=passwordexport MYSQL_PASS=passwordexport SERVICE_PASSWORD=passwordexport FIXED_RANGE=10.0.0.0/24export FLOATING_RANGE=$(/sbin/ifconfig eth0 | awk &apos;/inet addr/ {print $2}&apos; | cut -f2 -d &quot;:&quot; | awk -F &quot;.&quot; &apos;{print $1&quot;.&quot;$2&quot;.&quot;$3}&apos;).224/27export OS_AUTH_URL=&quot;http://localhost:5000/v2.0/&quot;export SERVICE_ENDPOINT=&quot;http://localhost:35357/v2.0&quot;export SERVICE_TOKEN=$(openssl rand -hex 10)export MASTER=&quot;$(/sbin/ifconfig eth0 | awk &apos;/inet addr/ {print $2}&apos; | cut -f2 -d &quot;:&quot;)&quot;EOF</code></pre><p>我的novarc内容，与原博客不同的是，出于某种原因我注释掉了两行，具体原因我也不是很清楚了2333。</p><pre><code>ubuntu@mu:~$ sudo cat /root/novarcexport OS_TENANT_NAME=adminexport OS_USERNAME=adminexport OS_PASSWORD=passwordexport MYSQL_PASS=passwordexport SERVICE_PASSWORD=passwordexport FIXED_RANGE=10.0.0.0/24export FLOATING_RANGE=10.210.0.94/27export OS_AUTH_URL=&quot;http://localhost:5000/v2.0/&quot;#export SERVICE_ENDPOINT=&quot;http://localhost:35357/v2.0&quot;#export SERVICE_TOKEN=a23debc939158820de0fexport MASTER=&quot;10.210.0.94&quot;</code></pre><p>确认没有问题或者进行修改，运行</p><pre><code>source novarcecho &quot;source novarc&quot;&gt;&gt;.bashrc</code></pre><h2 id="MYSQL"><a href="#MYSQL" class="headerlink" title="MYSQL"></a>MYSQL</h2><p>在Openstack组件里，Nova，Keystone, Glance, 都需要用到数据库。所以我们需要创建相关的数据库和用户。</p><table border="1" cellspacing="0" cellpadding="2" width="693"><br><tbody><br><tr><br><td valign="top" width="286"><strong>应用数据库</strong></td><br><td valign="top" width="216"><strong>数据库用户</strong></td><br><td valign="top" width="189"><strong>密码</strong></td><br></tr><br><tr><br><td valign="top" width="297">mysql</td><br><td valign="top" width="224">root</td><br><td valign="top" width="196">password</td><br></tr><br><tr><br><td valign="top" width="297">nova</td><br><td valign="top" width="227">nova</td><br><td valign="top" width="200">password</td><br></tr><br><tr><br><td valign="top" width="294">glance</td><br><td valign="top" width="228">glance</td><br><td valign="top" width="203">password</td><br></tr><br><tr><br><td valign="top" width="292">keystone</td><br><td valign="top" width="228">keystone</td><br><td valign="top" width="205">password</td><br></tr><br><tr><br><td valign="top" width="291">&nbsp;</td><br><td valign="top" width="227">&nbsp;</td><br><td valign="top" width="206">&nbsp;</td><br></tr><br><tr><br><td valign="top" width="291">&nbsp;</td><br><td valign="top" width="227">&nbsp;</td><br><td valign="top" width="207">&nbsp;</td><br></tr><br></tbody><br></table><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>mysql自动安装</p><pre><code>cat &lt;&lt;MYSQL_PRESEED | debconf-set-selectionsmysql-server-5.5 mysql-server/root_password password $MYSQL_PASSmysql-server-5.5 mysql-server/root_password_again password $MYSQL_PASSmysql-server-5.5 mysql-server/start_on_boot boolean trueMYSQL_PRESEED</code></pre><p>Openstack都是Python写的，所以你需要python-mysqldb，安装过程，就不会提示你输入root密码</p><pre><code>apt-get install -y mysql-server python-mysqldb</code></pre><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>编辑/etc/mysql/my.cnf, 允许网络访问mysql</p><pre><code>#bind-address           = 127.0.0.1bind-address            = 0.0.0.0</code></pre><p>或者直接运行下面命令</p><pre><code>sed -i &apos;s/127.0.0.1/0.0.0.0/g&apos; /etc/mysql/my.cnf</code></pre><p>重启mysql服务</p><pre><code>service mysql restart</code></pre><p>创建相关数据库</p><pre><code>mysql -uroot -p$MYSQL_PASS &lt;&lt;EOFCREATE DATABASE nova;GRANT ALL PRIVILEGES ON nova.* TO &apos;nova&apos;@&apos;%&apos; IDENTIFIED BY &apos;$MYSQL_PASS&apos;;CREATE DATABASE glance;GRANT ALL PRIVILEGES ON glance.* TO &apos;glance&apos;@&apos;%&apos; IDENTIFIED BY &apos;$MYSQL_PASS&apos;;CREATE DATABASE keystone;GRANT ALL PRIVILEGES ON keystone.* TO &apos;keystone&apos;@&apos;%&apos;IDENTIFIED BY &apos;$MYSQL_PASS&apos;;FLUSH PRIVILEGES;EOF</code></pre><h2 id="Keystone"><a href="#Keystone" class="headerlink" title="Keystone"></a>Keystone</h2><p>Keystone是Openstack的核心，所有的组件，都需要通过keystone进行认证和授权。</p><table border="0" cellspacing="0" cellpadding="2" width="400"><br><tbody><br><tr><br><td valign="top" width="100">租户（tenant）</td><br><td valign="top" width="100">用户</td><br><td valign="top" width="100">密码</td><br><td valign="top" width="100">&nbsp;</td><br></tr><br><tr><br><td valign="top" width="100">admin</td><br><td valign="top" width="100">admin</td><br><td valign="top" width="100">password</td><br><td valign="top" width="100">&nbsp;</td><br></tr><br><tr><br><td valign="top" width="100">service</td><br><td valign="top" width="100">nova</td><br><td valign="top" width="100">password</td><br><td valign="top" width="100">&nbsp;</td><br></tr><br><tr><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">glance</td><br><td valign="top" width="100">password</td><br><td valign="top" width="100">&nbsp;</td><br></tr><br><tr><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">&nbsp;</td><br></tr><br><tr><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">&nbsp;</td><br><td valign="top" width="100">&nbsp;</td><br></tr><br></tbody><br></table><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><pre><code>apt-get install -y keystone python-keystone python-keystoneclient</code></pre><h3 id="配置-1"><a href="#配置-1" class="headerlink" title="配置"></a>配置</h3><p>编辑/etc/keystone/keystone.conf，需要修改，注意数据库的连接IP和token根据自己的情况进行填写</p><ul><li>keystone的默认token是ADMIN，我这里修改成随机生成，查看novarc获得</li><li><p>默认是采用sqlite连接，我们需要改成mysql</p><!--你看不到我--><p>  [DEFAULT]<br>  #bind_host = 0.0.0.0<br>  public_port = 5000<br>  admin_port = 35357<br>  #admin_token = ADMIN<br>  admin_token = a23debc939158820de0f</p><p>  [database]<br>  #connection = sqlite:////var/lib/keystone/keystone.db<br>  connection = mysql://keystone:<a href="mailto:password@10.210.0.94" target="_blank" rel="noopener">password@10.210.0.94</a>/keystone<br>重启服务</p><p>  service keystone restart<br>同步keystone数据库</p><p>  keystone-manage db_sync</p></li></ul><p>keystone的数据库，需要导入数据和endpoint，你可以一步一步用命令行导入，可以参考keystone白皮书 <a href="http://www.canonical.com/about-canonical/resources/white-papers/configuring-keystone-openstack-essex" target="_blank" rel="noopener">http://www.canonical.com/about-canonical/resources/white-papers/configuring-keystone-openstack-essex</a></p><p>为了方便，你可以直接使用下面2个脚本来进行全部的设置。</p><ol><li><a href="http://www.chenshake.com/wp-content/uploads/2012/07/keystone_data.sh_.txt" target="_blank"> keystone_data.sh</a>导入用户信息</li><li><a href="http://www.chenshake.com/wp-content/uploads/2012/07/endpoints.sh_.txt" target="_blank">endpoints.sh</a>设置endpoint</li></ol><h3 id="Keystone-Data"><a href="#Keystone-Data" class="headerlink" title="Keystone Data"></a>Keystone Data</h3><pre><code>wget http://www.chenshake.com/wp-content/uploads/2012/07/keystone_data.sh_.txtmv keystone_data.sh_.txt keystone_data.shbash keystone_data.sh</code></pre><p>没任何输出，就表示正确，可以通过下面命令检查</p><pre><code>echo $?</code></pre><p>显示0，就表示脚本正确运行，千万不要重复运行脚本。</p><h3 id="Endpoint-导入"><a href="#Endpoint-导入" class="headerlink" title="Endpoint 导入"></a>Endpoint 导入</h3><pre><code>wget http://www.chenshake.com/wp-content/uploads/2012/07/endpoints.sh_.txtmv endpoints.sh_.txt endpoints.shbash endpoints.sh</code></pre><p>需要注意的是，这个脚本是假设你的glance服务和swift都是安装相同的服务器，如果你的glance在不同的服务器，你需要调整一下endpoint，可以在数据库里调整。</p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>可以使用curl命令来测试。</p><p>命令如下</p><pre><code>curl -d &apos;{&quot;auth&quot;: {&quot;tenantName&quot;: &quot;admin&quot;, &quot;passwordCredentials&quot;:{&quot;username&quot;: &quot;admin&quot;, &quot;password&quot;: &quot;password&quot;}}}&apos; -H &quot;Content-type:application/json&quot; http://$MASTER:35357/v2.0/tokens | python -mjson.tool</code></pre><p>你就可以获得一个24小时的token。（注意，上面的脚本没有创建demo用户，所以没法用demo账号去测试）</p><pre><code>&quot;token&quot;: {        &quot;expires&quot;: &quot;2012-09-27T02:09:37Z&quot;,         &quot;id&quot;: &quot;c719448800214e189da04772c2f75e23&quot;,         &quot;tenant&quot;: {            &quot;description&quot;: null,             &quot;enabled&quot;: true,             &quot;id&quot;: &quot;dc7ca2e51139457dada2d0f7a3719476&quot;,             &quot;name&quot;: &quot;admin&quot;        }</code></pre><p>通过下面命令，可以检查keystone的设置是否正确。</p><pre><code>root@node:~# keystone user-list+----------------------------------+---------+----------------------+--------+|                id                | enabled |        email         |  name  |+----------------------------------+---------+----------------------+--------+| 1189d15892d24e00827e707bd2b7ab07 | True    | admin@chenshake.com  | admin  || cca4a4ed1e8842db99239dc98fb1617f | True    | glance@chenshake.com | glance || daccc34eacc7493989cd13df93e7f6bc | True    | swift@chenshake.com  | swift  || ee57b02c535d44f48943de13831da232 | True    | nova@chenshake.com   | nova   |+----------------------------------+---------+----------------------+--------+    root@node17:~# keystone endpoint-list+----------------------------------+-----------+-----------------------------------------------+-----------------------------------------------+------------------------------------------+|                id                |   region  |                   publicurl                   |                  internalurl                  |                 adminurl                 |+----------------------------------+-----------+-----------------------------------------------+-----------------------------------------------+------------------------------------------+| 0b04e1baac1a4c9fb07490e0911192cf | RegionOne | http://10.1.199.17:5000/v2.0 | http://10.1.199.17:5000/v2.0 | http://10.1.199.17:35357/v2.0 || 0d3315627d52419fa08095f9def5d7e4 | RegionOne | http://10.1.199.17:8776/v1/%(tenant_id)s | http://10.1.199.17:8776/v1/%(tenant_id)s | http://10.1.199.17:8776/v1/%(tenant_id)s || 1c92290cba9f4a278b42dbdf2802096c | RegionOne | http://10.1.199.17:9292/v1 | http://10.1.199.17:9292/v1 | http://10.1.199.17:9292/v1 || 56fe83ce20f341d99fc576770c275586 | RegionOne | http://10.1.199.17:8774/v2/%(tenant_id)s | http://10.1.199.17:8774/v2/%(tenant_id)s | http://10.1.199.17:8774/v2/%(tenant_id)s || 5fb51aae00684e56818869918f86b564 | RegionOne | http://10.1.199.17:8080/v1/AUTH_%(tenant_id)s | http://10.1.199.17:8080/v1/AUTH_%(tenant_id)s | http://10.1.199.17:8080/v1 || aaac7663872d493b85d9e583329be9ed | RegionOne | http://10.1.199.17:8773/services/Cloud | http://10.1.199.17:8773/services/Cloud | http://10.1.199.17:8773/services/Admin |+----------------------------------+-----------+-----------------------------------------------+-----------------------------------------------+------------------------------------------+</code></pre><p>可以使用下面命令来查看结果</p><pre><code>keystone tenant-listkeystone user-listkeystone role-list</code></pre><h2 id="Glance"><a href="#Glance" class="headerlink" title="Glance"></a>Glance</h2><h3 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h3><pre><code>apt-get install -y glance glance-api glance-client glance-common glance-registry python-glance</code></pre><h3 id="配置-2"><a href="#配置-2" class="headerlink" title="配置"></a>配置</h3><p>编辑 <strong>/etc/glance/glance-api-paste.ini</strong> ，修改文档最后3行</p><pre><code>#admin_tenant_name = %SERVICE_TENANT_NAME%#admin_user = %SERVICE_USER%#admin_password = %SERVICE_PASSWORD%admin_tenant_name = serviceadmin_user = glanceadmin_password = password</code></pre><p>编辑 <strong>/etc/glance/glance-registry.conf</strong> 和  <strong>/etc/glance/glance-api.conf</strong> ，改成使用mysql验证，作如下修改，ip地址根据自己情况设置。</p><pre><code>[database]#sql_connection = sqlite:////var/lib/glance/glance.sqlitesql_connection = mysql://glance:password@10.210.0.94/glance[keystone_authtoken]auth_host = 10.210.0.94auth_port = 35357auth_protocol = httpadmin_tenant_name = serviceadmin_user = glanceadmin_password = password[paste_deploy]flavor=keystone</code></pre><p>重启glance服务</p><pre><code>service glance-api restart &amp;&amp; service glance-registry restart</code></pre><p>同步glance数据库</p><pre><code># glance-manage version_control 0# glance-manage db_sync/usr/lib/python2.7/dist-packages/glance/registry/db/migrate_repo/versions/003_add_disk_format.py:47: SADeprecationWarning: useexisting is deprecated.  Use extend_existing.useexisting=True)</code></pre><p>重启glance服务</p><pre><code>service glance-api restart &amp;&amp; service glance-registry restart</code></pre><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><pre><code>glance index</code></pre><p>没有输出，表示正常，因为目前还没有镜像。</p><h3 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h3><p>我们下载CirrOS的image作为测试使用，只有10M。如果是ubuntu官方的image，220M，并且ubuntu官方的image，都是需要使用密钥登陆。</p><h4 id="CirrOS"><a href="#CirrOS" class="headerlink" title="CirrOS"></a>CirrOS</h4><p>下载并上传image</p><pre><code>wget https://launchpad.net/cirros/trunk/0.3.0/+download/cirros-0.3.0-x86_64-disk.imgglance add name=cirros-0.3.0-x86_64 is_public=true  container_format=bare \disk_format=qcow2 &lt; /root/cirros-0.3.0-x86_64-disk.img</code></pre><p>Cirros，可以使用用户名和密码登陆，也可以使用密钥登陆</p><p>user:cirros \<br>password:cubswin:)</p><h4 id="Ubuntu官方image"><a href="#Ubuntu官方image" class="headerlink" title="Ubuntu官方image"></a>Ubuntu官方image</h4><p>下载并上传image</p><pre><code>wget http://cloud-images.ubuntu.com/precise/current/precise-server-cloudimg-amd64-disk1.imgglance add name=&quot;Ubuntu 12.04 cloudimg amd64&quot; is_public=true container_format=ovf \disk_format=qcow2 &lt; /root/precise-server-cloudimg-amd64-disk1.img</code></pre><p>user：ubuntu</p><p>只能使用密钥登陆。</p><h4 id="查看image"><a href="#查看image" class="headerlink" title="查看image"></a>查看image</h4><pre><code># glance indexID                                   Name                           Disk Format          Container Format     Size          ------------------------------------ ------------------------------ -------------------- -------------------- --------------5dcf84a0-b491-4710-8d7a-5531bce0dedc cirros-0.3.0-x86_64            qcow2                bare                        9761280f4f62d8a-3e5b-4136-8547-ce3cb79771aa Ubuntu 12.04 cloudimg amd64    qcow2                ovf                       230817792</code></pre><h2 id="Nova"><a href="#Nova" class="headerlink" title="Nova"></a>Nova</h2><h3 id="安装-3"><a href="#安装-3" class="headerlink" title="安装"></a>安装</h3><pre><code>apt-get install -y nova-api nova-cert nova-common nova-objectstore \nova-scheduler nova-volume nova-consoleauth novnc python-nova python-novaclient \nova-compute nova-compute-kvm  nova-network</code></pre><p>如果你希望控制节点，不打算跑计算服务，装完后，把nova compute的服务停掉也可以。</p><h3 id="配置-3"><a href="#配置-3" class="headerlink" title="配置"></a>配置</h3><p>编辑 <strong>/etc/nova/nova.conf</strong> 文件，</p><p>下面是我的nova.conf 文件的配置。</p><p>为了简单，大家直接copy下面内容，运行就可以，注意修改ip。</p><p>如果你是在虚拟机里安装，你需要把libvirt_type=kvm 改成 ibvirt_type=qemu</p><pre><code>[DEFAULT]dhcpbridge_flagfile=/etc/nova/nova.confdhcpbridge=/usr/bin/nova-dhcpbridgelogdir=/var/log/novastate_path=/var/lib/novalock_path=/var/lock/novaforce_dhcp_release=Trueiscsi_helper=tgtadmlibvirt_use_virtio_for_bridges=Trueconnection_type=libvirtroot_helper=sudo nova-rootwrap /etc/nova/rootwrap.confverbose=Trueec2_private_dns_show_ip=Trueapi_paste_config=/etc/nova/api-paste.inivolumes_path=/var/lib/nova/volumesenabled_apis=ec2,osapi_compute,metadatarpc_backend = rabbitrabbit_host = 10.210.0.94my_ip = 10.210.0.94vncserver_listen = 10.210.0.94vncserver_proxyclient_address = 10.210.0.94auth_strategy = keystone[keystone_authtoken]auth_uri = http://10.210.0.94:5000auth_host = 10.210.0.94auth_port = 35357auth_protocol = httpadmin_tenant_name = serviceadmin_user = novaadmin_password = password[database]connection = mysql://nova:password@10.210.0.94/nova</code></pre><p>设置目录权限</p><pre><code>chown -R nova:nova /etc/nova</code></pre><p>重启所有服务</p><pre><code>service rabbitmq-server restartservice libvirt-bin restartservice nova-scheduler restartservice nova-network restartservice nova-cert restartservice nova-compute restartservice nova-api restartservice nova-objectstore restartservice nova-volume restart</code></pre><p>也可以使用下面脚本进行重启</p><pre><code>#!/bin/bashfor a in rabbitmq-server libvirt-bin nova-network nova-cert nova-compute \nova-api nova-objectstore nova-scheduler nova-volume \novnc  nova-consoleauth; do service &quot;$a&quot; stop; donefor a in rabbitmq-server libvirt-bin nova-network nova-cert nova-compute \nova-api nova-objectstore nova-scheduler nova-volume \novnc  nova-consoleauth; do service &quot;$a&quot; start; done</code></pre><p>运行脚本</p><pre><code>bash restart.shStopping rabbitmq-server: rabbitmq-server.libvirt-bin stop/waitingnova-network stop/waitingnova-cert stop/waitingnova-compute stop/waitingnova-api stop/waitingnova-objectstore stop/waitingnova-scheduler stop/waitingnova-volume stop/waiting* Stopping OpenStack NoVNC proxy nova-novncproxy                 [ OK ] nova-consoleauth stop/waitingStarting rabbitmq-server: SUCCESSrabbitmq-server.libvirt-bin start/running, process 9683nova-network start/running, process 9703nova-cert start/running, process 9713nova-compute start/running, process 9724nova-api start/running, process 9734nova-objectstore start/running, process 9744nova-scheduler start/running, process 9759nova-volume start/running, process 9775* Starting OpenStack NoVNC proxy  nova-novncproxy                 [ OK ] nova-consoleauth start/running, process 9839</code></pre><p>同步数据库</p><pre><code>nova-manage db sync</code></pre><p>会有一堆的输出，不过应该是没问题的。nova数据库里已经有相应的表，就表示正确。</p><pre><code># nova-manage db sync2012-07-19 18:43:34 WARNING nova.utils [-] /usr/lib/python2.7/dist-packages/sqlalchemy/pool.py:639: SADeprecationWarning: The &apos;listeners&apos; argument to Pool (and create_engine()) is deprecated.  Use event.listen().Pool.__init__(self, creator, **kw)2012-07-19 18:43:34 WARNING nova.utils [-] /usr/lib/python2.7/dist-packages/sqlalchemy/pool.py:145: SADeprecationWarning: Pool.add_listener is deprecated.  Use event.listen()self.add_listener(l)2012-07-19 18:43:34 AUDIT nova.db.sqlalchemy.fix_dns_domains [-] Applying database fix for Essex dns_domains table.</code></pre><h3 id="创建fix-IP"><a href="#创建fix-IP" class="headerlink" title="创建fix IP"></a>创建fix IP</h3><p>FIX IP，就是分配给虚拟机的实际IP地址。这些数据都会写入数据库。$FIXED_RANGE 在novarc里设置。</p><pre><code>nova-manage network create private --fixed_range_v4=$FIXED_RANGE \--num_networks=1 --bridge=br100 --bridge_interface=eth1 \--network_size=256 --multi_host=T</code></pre><h3 id="创建floating-IP"><a href="#创建floating-IP" class="headerlink" title="创建floating IP"></a>创建floating IP</h3><p>所谓Floating IP，是亚马逊EC2的定义。简单说，就是公网的IP。他其实是通过类似防火墙类似，做一个映射。实际上是通过iptables来实现映射.</p><pre><code>nova-manage floating create --ip_range=$FLOATING_RANGE</code></pre><p>重启nova服务</p><pre><code>bash restart.sh libvirt-bin stop/waitingnova-network stop/waitingnova-cert stop/waitingnova-compute stop/waitingnova-api stop/waitingnova-objectstore stop/waitingnova-scheduler stop/waitingnova-volume stop/waiting* Stopping OpenStack NoVNC proxy nova-novncproxy                                           [ OK ] nova-consoleauth stop/waitinglibvirt-bin start/running, process 23232nova-network start/running, process 23252nova-cert start/running, process 23262nova-compute start/running, process 23273nova-api start/running, process 23285nova-objectstore start/running, process 23303nova-scheduler start/running, process 23321nova-volume start/running, process 23336* Starting OpenStack NoVNC proxy  nova-novncproxy                                          [ OK ] nova-consoleauth start/running, process 23386</code></pre><h2 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h2><p>可以尝试用下面命令去检查nova的状况</p><p>nova-manage service list</p><p>若state均为:-） \<br>说明安装成功</p><h4 id="命令行创建虚拟机的过程"><a href="#命令行创建虚拟机的过程" class="headerlink" title="命令行创建虚拟机的过程"></a>命令行创建虚拟机的过程</h4><pre><code>nova keypair-add oskey &gt; oskey.privchmod 600 oskey.privnova flavor-listnova image-listnova boot --flavor 2 --key_name oskey --image ea3ffba1-065e-483f-bfe2-c84184ee76be test1nova secgroup-add-rule default tcp 22 22 0.0.0.0/0nova secgroup-add-rule default icmp -1 -1 0.0.0.0/0</code></pre><p>这个时候，你在服务器上可以直接ssh到虚拟机上，ubuntu的虚拟机，用户是ubuntu。虚拟机的Ip</p><pre><code># nova list+--------------------------------------+-------+--------+------------------+|                  ID                  |  Name | Status |     Networks     |+--------------------------------------+-------+--------+------------------+| 61e93d62-c926-46fa-8e0c-48073b7e58b0 | test1 | ACTIVE | private=10.0.0.2 || 6976e539-32d9-48a6-9fb5-28a3cdb55f71 | test2 | ACTIVE | private=10.0.0.4 |+--------------------------------------+-------+--------+------------------+</code></pre><p>在服务器上直接ssh到虚拟机，如果你在远程，就需要分配floating IP。</p><pre><code>ssh -i oskey.priv ubuntu@10.0.0.4</code></pre><p>登陆虚拟机后，你可以查看一下路由</p><pre><code>$ routeKernel IP routing tableDestination     Gateway         Genmask         Flags Metric Ref    Use Ifacedefault         10.0.0.3        0.0.0.0         UG    100    0        0 eth010.0.0.0        *               255.255.255.0   U     0      0        0 eth0</code></pre><p>显示网关是10.0.0.3，这个时候，你看一下</p><pre><code>root@node:~# ifconfigbr100   Link encap:Ethernet  HWaddr 00:e0:81:d8:4a:23          inet addr:10.0.0.3  Bcast:10.0.0.255  Mask:255.255.255.0        inet6 addr: fe80::ccfc:5aff:fef5:4345/64 Scope:Link</code></pre><p>需要注意的是：br100的IP，需要你创建第一个虚拟机，他才会获得IP。</p><h2 id="Dashobard"><a href="#Dashobard" class="headerlink" title="Dashobard"></a>Dashobard</h2><h3 id="安装-4"><a href="#安装-4" class="headerlink" title="安装"></a>安装</h3><pre><code>apt-get install -y apache2 libapache2-mod-wsgi openstack-dashboard</code></pre><p>重启nova api</p><pre><code>restart nova-api</code></pre><p>这个时候，就可以访问dashboard。</p><h2 id="测试-3"><a href="#测试-3" class="headerlink" title="测试"></a>测试</h2><p>登陆dashobard，下面地址是我的horizon界面，可以直接访问，注：需要北航内网。</p><p><a href="http://10.210.0.94/horizon" target="_blank" rel="noopener">http://10.210.0.94/horizon</a> \<br>user:admin \<br>pass:password</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;OpenStack单节点单网卡安装&quot;&gt;&lt;a href=&quot;#OpenStack单节点单网卡安装&quot; class=&quot;headerlink&quot; title=&quot;OpenStack单节点单网卡安装&quot;&gt;&lt;/a&gt;OpenStack单节点单网卡安装&lt;/h1&gt;&lt;h3 id=&quot;参考陈沙克
      
    
    </summary>
    
    
      <category term="OpenStack" scheme="http://yoursite.com/tags/OpenStack/"/>
    
  </entry>
  
  <entry>
    <title>使用kubeadm搭建kubernetes集群</title>
    <link href="http://yoursite.com/2018/10/08/2_%E4%BD%BF%E7%94%A8kubeadm%E6%90%AD%E5%BB%BAkubernetes%E9%9B%86%E7%BE%A4/"/>
    <id>http://yoursite.com/2018/10/08/2_使用kubeadm搭建kubernetes集群/</id>
    <published>2018-10-08T14:29:05.109Z</published>
    <updated>2018-09-16T05:08:21.395Z</updated>
    
    <content type="html"><![CDATA[<h1 id="使用kubeadm搭建kubernetes集群"><a href="#使用kubeadm搭建kubernetes集群" class="headerlink" title="使用kubeadm搭建kubernetes集群"></a>使用kubeadm搭建kubernetes集群</h1><h3 id="参考kubernetes官方文档"><a href="#参考kubernetes官方文档" class="headerlink" title="参考kubernetes官方文档"></a>参考kubernetes官方文档</h3><p><a href="https://kubernetes.io/docs/setup" target="_blank" rel="noopener">https://kubernetes.io/docs/setup</a></p><h3 id="作者：薛世卿"><a href="#作者：薛世卿" class="headerlink" title="作者：薛世卿"></a>作者：薛世卿</h3><p>如遇安装问题，可以咨询我。</p><p>注意：本文安装过程为在线安装，需要科学上网</p><h2 id="一、网络配置"><a href="#一、网络配置" class="headerlink" title="一、网络配置"></a>一、网络配置</h2><p>使用shadowsocks配置本地代理后，服务器可以访问外网。与通常的shadowsocks（下简称ss）客户端配置不同，Linux系统还需要polipo完成socks 5协议到HTTP协议的转换。</p><h3 id="安装shadowsocks"><a href="#安装shadowsocks" class="headerlink" title="安装shadowsocks"></a>安装shadowsocks</h3><p>由于ss是基于Python开发，我们首先需要安装Python。Python2和Python3皆可，但需要注意Py2和3的版本冲突问题，不要重复安装。</p><p>确定系统中无Python后</p><pre><code>sudo apt-get install python</code></pre><p>安装包管理应用pip（Py3安装pip3）</p><pre><code>sudo apt-get install python-pip</code></pre><p>安装完毕之后，通过pip直接安装ss</p><pre><code>sudo pip install shadowsocks</code></pre><h3 id="配置shadowsocks客户端"><a href="#配置shadowsocks客户端" class="headerlink" title="配置shadowsocks客户端"></a>配置shadowsocks客户端</h3><p>新建一个配置文件client.json，配置相应参数</p><pre><code>{    &quot;server&quot;:&quot;{your-ss-server-ip}&quot;,    &quot;server_port&quot;:{your-ss-server-port},    &quot;local_port&quot;:1080,    &quot;password&quot;:&quot;{your-password}&quot;,    &quot;timeout&quot;:600,    &quot;method&quot;:&quot;aes-256-cfb&quot;}</code></pre><p>启动ss客户端</p><pre><code>sudo sslocal -c client.json -d start</code></pre><p>如何配置ss服务器端不在本文讨论范围之内。</p><h3 id="配置全局代理"><a href="#配置全局代理" class="headerlink" title="配置全局代理"></a>配置全局代理</h3><p>我们需要polipo完成socks 5和HTTP协议间的转换。首先是安装polipo。</p><pre><code>sudo apt-get install polipo</code></pre><p>修改polipo的配置文件/etc/polipo/config</p><pre><code>logSyslog = truelogFile = /var/log/polipo/polipo.logproxyAddress = &quot;0.0.0.0&quot;socksParentProxy = &quot;127.0.0.1:1080&quot;socksProxyType = socks5chunkHighMark = 50331648objectHighMark = 16384serverMaxSlots = 64serverSlots = 16serverSlots1 = 32</code></pre><p>重启polipo</p><pre><code>sudo /etc/init.d/polipo restart</code></pre><p>为终端配置http代理（只对当前终端生效的临时环境变量）</p><pre><code>export http_proxy=&quot;http://127.0.0.1:8123/&quot;</code></pre><p>此时为全局代理模式，如果需要关闭代理，删除环境变量即可，命令如下</p><pre><code>unset http_proxy</code></pre><p>测试代理</p><pre><code>curl www.google.com</code></pre><p>重启服务器后，通常需要重新执行下面的指令来使用代理</p><pre><code>sudo sslocal -c client.json -d startexport http_proxy=&quot;http://127.0.0.1:8123/&quot;</code></pre><p>此时通过Debian的apt-get命令就可以访问docker.io和kubernetes.io，畅通地完成以下安装过程。</p><h2 id="二、安装kubeadm"><a href="#二、安装kubeadm" class="headerlink" title="二、安装kubeadm"></a>二、安装kubeadm</h2><p>本章节介绍了如何通过kubeadm搭建集群</p><h3 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h3><ul><li>关闭防火墙规则</li><li>关闭交换分区</li><li>确认端口占用</li></ul><p>首先，查看防火墙规则</p><pre><code>iptables -L</code></pre><p>如果有可能影响到节点通信的规则，可以通过以下命令放开iptables规则（注意，此操作可能会导致ssh连接永久掉线，请慎重操作,为了稳妥起见可以只执行后三条命令）</p><pre><code>iptables -F //清除规则链中已有条目iptables -X //清除自定义规则iptables -Z //清空数据表计算器和字节计数器iptables -P INPUT ACCEPTiptables -P OUTPUT ACCEPTiptables -P FORWARD ACCEPTiptables-save</code></pre><p>然后，关闭各个节点上的swap分区</p><pre><code>swapoff -a</code></pre><p>注释掉swap分区</p><pre><code>vi /etc/fstab#/dev/mapper/c1-swap  swap  swap  defaults    0 0</code></pre><p>kubernetes服务端口占用情况如下</p><h3 id="Master-node-s"><a href="#Master-node-s" class="headerlink" title="Master node(s)"></a>Master node(s)</h3><table><thead><tr><th>Protocol</th><th>Direction</th><th>Port Range</th><th>Purpose</th><th>Used By</th></tr></thead><tbody><tr><td>TCP</td><td>Inbound</td><td>6443*</td><td>Kubernetes API server</td><td>All</td></tr><tr><td>TCP</td><td>Inbound</td><td>2379-2380</td><td>etcd server client API</td><td>kube-apiserver, etcd</td></tr><tr><td>TCP</td><td>Inbound</td><td>10250</td><td>Kubelet API</td><td>Self, Control plane</td></tr><tr><td>TCP</td><td>Inbound</td><td>10251</td><td>kube-scheduler</td><td>Self</td></tr><tr><td>TCP</td><td>Inbound</td><td>10252</td><td>kube-controller-manager</td><td>Self</td></tr></tbody></table><h3 id="Worker-node-s"><a href="#Worker-node-s" class="headerlink" title="Worker node(s)"></a>Worker node(s)</h3><table><thead><tr><th>Protocol</th><th>Direction</th><th>Port Range</th><th>Purpose</th><th>Used By</th></tr></thead><tbody><tr><td>TCP</td><td>Inbound</td><td>10250</td><td>Kubelet API</td><td>Self, Control plane</td></tr><tr><td>TCP</td><td>Inbound</td><td>30000-32767</td><td>NodePort Services**</td><td>All</td></tr></tbody></table><p>** Default port range for NodePort Services.</p><p>Any port numbers marked with * are overridable, so you will need to ensure any custom ports you provide are also open.</p><p>Although etcd ports are included in master nodes, you can also host your own etcd cluster externally or on custom ports.</p><p>The pod network plugin you use (see below) may also require certain ports to be open. Since this differs with each pod network plugin, please see the documentation for the plugins about what port(s) those need.</p><h3 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h3><p>请确保http代理已设置，即已经设置了$http_proxy</p><p>安装Docker CE 17.03</p><pre><code>apt-get updateapt-get install -y apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL http://download.docker.com/linux/ubuntu/gpg | apt-key add -add-apt-repository &quot;deb http://download.docker.com/linux/$(. /etc/os-release; echo &quot;$ID&quot;) $(lsb_release -cs) stable&quot;apt-get update &amp;&amp; apt-get install -y docker-ce=$(apt-cache madison docker-ce | grep 17.03 | head -1 | awk &apos;{print $3}&apos;)</code></pre><h3 id="安装kubeadm，kubelet和kubectl"><a href="#安装kubeadm，kubelet和kubectl" class="headerlink" title="安装kubeadm，kubelet和kubectl"></a>安装kubeadm，kubelet和kubectl</h3><p>你将会在机器上安装如下组件</p><ul><li><strong>kubeadm</strong>： the command to bootstrap the cluster.</li><li><strong>kubelet</strong>: the component that runs on all of the machines in your cluster and does things like starting pods and containers.</li><li><p><strong>kubectl</strong>: the command line util to talk to your cluster.</p><!-- 你还是看不见我 --> <p>  apt-get update &amp;&amp; apt-get install -y apt-transport-https curl<br>  curl -s <a href="http://packages.cloud.google.com/apt/doc/apt-key.gpg" target="_blank" rel="noopener">http://packages.cloud.google.com/apt/doc/apt-key.gpg</a> | apt-key add -<br>  cat &lt;<eof>/etc/apt/sources.list.d/kubernetes.list<br>  deb <a href="http://apt.kubernetes.io/" target="_blank" rel="noopener">http://apt.kubernetes.io/</a> kubernetes-xenial main<br>  EOF<br>  apt-get update<br>  apt-get install -y kubelet=1.10.4-00 kubeadm=1.10.4-00 kubectl=1.10.4-00 kubernetes-cni<br>  apt-mark hold kubelet kubeadm kubectl kubernetes-cni</eof></p></li></ul><h3 id="设置docker代理"><a href="#设置docker代理" class="headerlink" title="设置docker代理"></a>设置docker代理</h3><p>为了避免docker拉取镜像时发生网络错误，进行如下设置。</p><pre><code>vi /etc/default/docker</code></pre><p>添加以下内容</p><pre><code>HTTP_PROXY=&quot;http://127.0.0.1:8123/&quot;HTTPS_PROXY=&quot;https://127.0.0.1:8123/&quot;export HTTP_PROXY HTTPS_PROXY</code></pre><p>编辑docker.server</p><pre><code>EnvironmentFile=-/etc/default/dockerExecStart=/usr/bin/docker daemon -H fd:// $DOCKER_OPTS</code></pre><p>重启docker</p><pre><code>systemctl daemon-reloadsystemctl restart docker.service</code></pre><h3 id="主节点初始化"><a href="#主节点初始化" class="headerlink" title="主节点初始化"></a>主节点初始化</h3><p>在主节点上，执行如下命令</p><pre><code>kubeadm init --kubernetes-version=1.10.4-00 --pod-network-cidr=10.244.0.0/16</code></pre><p>如果执行失败，可以查看kubelet的运行状况，一般是由于kubelet运行失败导致的。</p><pre><code>systemctl status kubelet</code></pre><p>大致显示如下内容</p><pre><code>[init] Using Kubernetes version: v1.10.4    [init] Using Authorization modes: [Node RBAC][preflight] Running pre-flight checks.[WARNING FileExisting-crictl]: crictl not found in system path[certificates] Using the existing ca certificate and key.[certificates] Using the existing apiserver certificate and key.[certificates] Using the existing apiserver-kubelet-client certificate and key.[certificates] Using the existing sa key.[certificates] Using the existing front-proxy-ca certificate and key.[certificates] Using the existing front-proxy-client certificate and key.[certificates] Valid certificates and keys now exist in &quot;/etc/kubernetes/pki&quot;[kubeconfig] Using existing up-to-date KubeConfig file: &quot;admin.conf&quot;[kubeconfig] Using existing up-to-date KubeConfig file: &quot;kubelet.conf&quot;[kubeconfig] Using existing up-to-date KubeConfig file: &quot;controller-manager.conf&quot;[kubeconfig] Using existing up-to-date KubeConfig file: &quot;scheduler.conf&quot;[controlplane] Wrote Static Pod manifest for component kube-apiserver to &quot;/etc/kubernetes/manifests/kube-apiserver.yaml&quot;[controlplane] Wrote Static Pod manifest for component kube-controller-manager to &quot;/etc/kubernetes/manifests/kube-controller-manager.yaml&quot;[controlplane] Wrote Static Pod manifest for component kube-scheduler to &quot;/etc/kubernetes/manifests/kube-scheduler.yaml&quot;[etcd] Wrote Static Pod manifest for a local etcd instance to &quot;/etc/kubernetes/manifests/etcd.yaml&quot;[init] Waiting for the kubelet to boot up the control plane as Static Pods from directory &quot;/etc/kubernetes/manifests&quot;.[init] This might take a minute or longer if the control plane images have to be pulled.[apiclient] All control plane components are healthy after 27.003370 seconds[uploadconfig] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace[markmaster] Will mark node master1 as master by adding a label and a taint[markmaster] Master master1 tainted and labelled with key/value: node-role.kubernetes.io/master=&quot;&quot;[bootstraptoken] Using token: d405c1.18b51150e22ffe72[bootstraptoken] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials[bootstraptoken] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token[bootstraptoken] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster[bootstraptoken] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace[addons] Applied essential addon: kube-dns[addons] Applied essential addon: kube-proxyYour Kubernetes master has initialized successfully!To start using your cluster, you need to run the following as a regular user:mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/configYou should now deploy a pod network to the cluster.Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:https://kubernetes.io/docs/concepts/cluster-administration/addons/You can now join any number of machines by running the following on each nodeas root:kubeadm join --token d405c1.18b51150e22ffe72 192.168.128.26:6443 --discovery-token-ca-cert-hash sha256:936229f8381de8df72e8b0de8a349a0099f0d0fc0407ca17a5bffe2e6</code></pre><p>请记录下最后一句话，它将是之后加入节点的指令（非常重要），之后执行下面的命令</p><pre><code>mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config</code></pre><p>对于root用户</p><pre><code>export KUBECONFIG=/etc/kubernetes/admin.conf</code></pre><p>也可以直接放到~/.bash_profile</p><pre><code>echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</code></pre><p>修改网桥设置</p><pre><code>sysctl net.bridge.bridge-nf-call-iptables=1</code></pre><p>安装网络组件Flannel</p><pre><code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml</code></pre><p>查看节点</p><pre><code>kubectl get nodes</code></pre><p>此时master节点不作为工作节点，如果你希望pods也能够调度到master节点上，执行以下命令</p><pre><code>kubectl taint nodes --all node-role.kubernetes.io/master-</code></pre><h2 id="添加node节点"><a href="#添加node节点" class="headerlink" title="添加node节点"></a>添加node节点</h2><p>首先网络设置同master节点，并按同样的方式完成kubeadm，kubelet,kubernetes-cni的安装，保证各节点可以互相通信。</p><p>进入root用户，运行刚才记录下来的kubeadm join …命令</p><pre><code>kubeadm join --token d405c1.18b51150e22ffe72 192.168.128.26:6443 --discovery-token-ca-cert-hash sha256:936229f8381de8df72e8b0de8a349a0099f0d0fc0407ca17a5bffe2e6</code></pre><p>如果运行失败，在下次运行前，需要停止kubelet服务对端口的占用，同时按照提示删除生成的一些文件，如etcd文件夹下面的一些内容，重新运行即可。</p><p>运行成功后，通过以下命令可以看到加入的节点</p><pre><code>kubectl get nodes</code></pre><h2 id="三、配置DashBoard"><a href="#三、配置DashBoard" class="headerlink" title="三、配置DashBoard"></a>三、配置DashBoard</h2><p>由于新版本的kubernetes加入了rbac，非本机访问DashBoard会遇到权限上的问题。</p><p>我们采用的方法是直接创建admin用户无视认证过程，不然就需要配置证书，过程颇为复杂。</p><p>创建dashboard-admin.yaml</p><pre><code>apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata:  name: kubernetes-dashboard  labels:    k8s-app: kubernetes-dashboardroleRef:  apiGroup: rbac.authorization.k8s.io  kind: ClusterRole  name: cluster-adminsubjects:- kind: ServiceAccount  name: kubernetes-dashboard  namespace: kube-system</code></pre><p>安装DashBoard</p><pre><code>kubectl create -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</code></pre><p>创建admin用户</p><pre><code>kubectl apply -f dashboard-admin.yaml</code></pre><p>master节点运行kubectl代理</p><pre><code>kubectl proxy --address=&apos;{master-ip}&apos; --disable-filter=true</code></pre><p>启动后，访问以下地址</p><pre><code>http://{your-master-ip}:8001/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy/</code></pre><p>跳过登录即可</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;使用kubeadm搭建kubernetes集群&quot;&gt;&lt;a href=&quot;#使用kubeadm搭建kubernetes集群&quot; class=&quot;headerlink&quot; title=&quot;使用kubeadm搭建kubernetes集群&quot;&gt;&lt;/a&gt;使用kubeadm搭建kubern
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://yoursite.com/tags/kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>你好，Hexo</title>
    <link href="http://yoursite.com/2018/05/13/%E4%BD%A0%E5%A5%BD%EF%BC%8CHexo/"/>
    <id>http://yoursite.com/2018/05/13/你好，Hexo/</id>
    <published>2018-05-13T14:23:13.000Z</published>
    <updated>2018-05-13T14:23:13.092Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
</feed>
